---
knit: (function(input_file, encoding) {
  out_dir <- 'docs/R';
  rmarkdown::render(input_file,
    encoding=encoding,
    output_file='Likert-scale.md') })
output: github_document
editor_options:
  chunk_output_type: console
---
  
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=TRUE, message = FALSE,
                      fig.path="img/Likert-scale/",
                      fig.width=6, fig.height=4,
                      fig.show='hold', fig.align='center'
                      )
options(width=100)
```

# Likert scale analysis

&emsp;For this tutorial we will be using a [modified data set](https://github.com/tylerbg/DLC_stat_resources/blob/master/docs/R/dat/wiki4HE_rev.csv) that contains Likert responses collected from faculty at the Open University of Catalonia on their opinions for using Wikipedia as a teaching resource.  The data set was originally provided by the [UCI Maching Learning Repository](https://archive.ics.uci.edu/ml/datasets/wiki4he).

```{r load_data}
wiki.dat <- read.csv("dat/wiki4HE_rev.csv", stringsAsFactors = TRUE)
```

&emsp;With Likert scale analysis we take a group of Likert items and sum (or average) their scores for each respondent.  This method is beneficial when we are not interested in how respondents answer some specific question but rather the opinion of respondents on a broader topic.  

&emsp;For example, instead of hypothesizing that respondents will answer the question "Articles in Wikipedia are reliable" will be more or lesser in one group than another, we can create and combine similar questions to get a broader sense on how people view the 'quality' of Wikipedia.

```{r Qu_plot1, echo = FALSE, results = FALSE, message = FALSE}
library(tidyverse)
library(likert)

Qu.items <- wiki.dat %>% select(Qu1:Qu5)
names(Qu.items) <- c("Quality 1: Articles in Wikipedia are reliable",
                     "Quality 2: Articles in Wikipedia are updated",
                     "Quality 3: Articles in Wikipedia are comprehensive",
                     "Quality 4: In my area of expertise, Wikipedia has a lower quality than other educational resources",
                     "Quality 5: I trust in the editing system of Wikipedia"
                     )
cols <- names(Qu.items)
Qu.items[cols] <- lapply(Qu.items[cols], factor, order = TRUE)

likert.res <- likert(items = Qu.items)
plot(likert.res,
     low.color = "goldenrod",
     high.color = "steelblue",
     group.order = cols
     )
```

### Comparing two groups

&emsp;Suppose we are interested if two groups respond differently regarding their attitudes toward a subject.  For example, let us question whether males and females view the quality of Wikipedia articles differently.

&emsp;First we take the sum (or alternatively the average) of the responses for each respondent in the question group of interest.  An easy way to perform this in R is to use the `rowSums()` function to create a new variable (column) that sums the scores of all questions belonging to our topic, which in this case would be all of the quality (`Qu`) questions.

```{r}
wiki.dat$Qu <- rowSums(wiki.dat[, c("Qu1", "Qu2", "Qu3", "Qu4", "Qu5")])
```

&emsp;Comparing the distributions of the summed Likert responses below, it is difficult to determine whether there is a different between how males and females view the quality of Wikipedia.

```{r Qu_GENDER_plot, echo = FALSE}
wiki.dat$Qu <- rowSums(wiki.dat[, c("Qu1", "Qu2", "Qu3", "Qu4", "Qu5")])
ggplot(wiki.dat, aes(x = GENDER, y = Qu)) +
  geom_jitter(alpha = 0.25, width = 0.1, height = 0,
              aes(color = GENDER)) +
  stat_summary(fun.data = "mean_sdl",
               geom = "pointrange",
               size = 1, shape = 3
               ) +
  scale_shape_manual(values = c("-", "-")) +
  # geom_violin() +
  # geom_dotplot(binaxis = "y", stackdir = "center", dotsize = 0.4) +
  theme_classic() +
  labs(x = "Gender",
       y = "Sum of Quality Scores") +
  theme(legend.position = "none")
```

&emsp;Therefore, we should employ some statistical test to help us determine if there are differences to how their genders view Wikipedia article quality.  When we combine multiple Likert-type responses into a single score (at least 4 or 5 items), the distribution of the scores changes from a clear ordinal scale to a more approximately normal distribution.  Thus, thanks to the [Central Limit Theorum](https://online.stat.psu.edu/stat414/lesson/27/27.1), we can employ parametric tests as long as our sample size is large.  Our data set contains 796 respondents which is plenty large enough to meet this condition.

&emsp;The parametric test we can employ then is the t-test, which we can run using the `t.test()` function with the formula "scores ~ group".

```{r t_test}
t.test(Qu ~ GENDER, data = wiki.dat)
```

&emsp;From the results of the t-test (p-value less than 0.05) we can conclude that there is a statistically significant difference between the mean responses of how males and females view the quality of Wikipedia articles.  While we can see from the `sample estimates` that males rate higher on average than females, the difference is quite small and the survey was originally on an ordinal scale, so the numerical difference between our two groups has little meaning for us.  The big take away is that males tend to (at least slightly) view the quality of Wikipedia articles higher than females based on the five questions provided in our survey.  

### Comparing multiple groups

&emsp;Now let us test the hypothesis that there are differences in how respondents among our six scholarly domains view the quality of Wikipedia articles.

```{r Qu_DOMAIN_plot, echo = FALSE}
wiki.sub.qu <- wiki.dat %>% dplyr::select(DOMAIN, Qu)
wiki.sub.qu$DOMAIN <- factor(wiki.sub.qu$DOMAIN, levels = c("Arts & Humanities",
                                                            "Engineering & Architecture",
                                                            "Health Sciences",
                                                            "Law & Politics",
                                                            "Sciences",
                                                            "Other"),
                             ordered = TRUE)
ggplot(wiki.sub.qu, aes(x = DOMAIN, y = Qu, group = DOMAIN)) +
  stat_summary(fun.data = "mean_sdl",
               geom = "pointrange",
               size = 1, shape = 3) +
  geom_jitter(alpha = 0.5, width = 0.25, aes(color = DOMAIN)) +
  theme_classic() +
  labs(x = NULL,
       y = "Sum of Quality Scores") +
  theme(legend.position = "none",
        axis.text.x = element_text(angle = 30, vjust = 1, hjust = 1))
```

&emsp;To test our hypothesis, we can employ the one-way ANOVA test using the `aov()` command using similar formula syntax as with the t-test.  We can also set the results as an object to use with later functions.  Importantly, we will first look at residual plots using `plot()` to observe how well the ANOVA model fit then use `summary()` to see a table of the results.  We will also use `par(mfrow=c(2,2))` so that all four diagnostic plots are drawn in the same frame.

```{r aov}
domain.fit <- aov(lm(Qu ~ DOMAIN, data = wiki.dat))

par(mfrow=c(2,2))
plot(domain.fit)

summary(domain.fit)
```

&emsp;From the plots there are no notable patterns and the points follow along the dashed line in the normal Q-Q plot, suggesting a good fit.  In the results table we see that there is a statistically significant difference in the scores between at least some of the domains, but which ones?  We will need to follow up our ANOVA with a post-hoc test, in this case Tukey's honestly significant difference (HSD) test which we can do with the `TukeyHSD()` function.

```{r TukeyHSD}
TukeyHSD(domain.fit)
```



### Relationships between responses




```{r use_vs_qu, echo = FALSE}
wiki.dat$Use <- rowSums(wiki.dat[, c("Use1", "Use2", "Use3", "Use4", "Use5")])

ggplot(wiki.dat, aes(x = Qu, y = Use)) +
  geom_density2d(color = "steelblue") +
  geom_point(alpha = 0.1) +
  theme_bw()
```



```{r}
wiki.dat$Use <- rowSums(wiki.dat[, c("Use1", "Use2", "Use3", "Use4", "Use5")])

use.qu.fit <- lm(Use ~ Qu, data = wiki.dat)
summary(use.qu.fit)
plot(use.qu.fit)
```





