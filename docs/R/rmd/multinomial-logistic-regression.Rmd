---
knit: (function(input_file, encoding) {
  out_dir <- 'docs/R';
  rmarkdown::render(input_file,
    encoding=encoding,
    output_file='../multinomial-logistic-regression.md') })
output:
  html_document:
    highlight: tango
editor_options:
  chunk_output_type: console
---
  
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=TRUE, fig.path="../img/multinomial-logistic-regression/",
                      fig.width=6, fig.height=4,
                      fig.show='hold', fig.align='center')
options(width=100)
```

# Multinomial Logistic Regression in `R`

For this guide we will be using a [data set](https://github.com/tylerbg/DLC_stat_resources/tree/master/docs/R/dat/teaching-methods.csv) that assesses different teaching methods, originally provided by [Minitab](https://support.minitab.com/en-us/minitab/21/help-and-how-to/statistical-modeling/regression/how-to/nominal-logistic-regression/before-you-start/example/).  This data set was collected by a school administrator who asked 30 different children their favorite subject and teaching method, who wanted to know if children's favorite subjects varied on their age and favored teaching method.  The data set includes 3 variables:

* *Subject* - the child's favorite subject of either *Arts*, *Math*, or *Science*.
* *Teaching.Method* - the child's favorite teaching methods of either *Demonstrate* or *Explain*.
* *Age* - the age of the child surveyed.

To begin we will load in the data using `read.csv()`, then take a quick look at the first few rows with `head()`

```{r}
teach <- read.csv("../../dat-source/teaching-methods.csv")

head(teach)
```

As we can see from the output above, each row is an individual observation.  To fit our data into a multinomial logistic model we will need to employ an external package.  The `nnet` package, which includes a host of tools for classification and neural network models, is a commonly used library for multinominal models, however here we will instead use the `VGAM` package.

After loading the `VGAM` package we can fit the multinomial model using `vglm()` where we include the typical model formula with the response variable *Subject* on the left and the predictor variables *Teaching.Method* and *Age* (using `.` as shorthand to include all other columns in the data set) on the right of a `~`.  Additionally, we will set the `family` argument to `multinomial`.

```{r}
library(VGAM)

teach_mlr <- vglm(Subject ~ Teaching.Method * Age, data = teach, family = multinomial)
```

```{r}
summary(teach_mlr)

anova(teach_mlr, test = "LR")
```




```{r}
teach <- read.csv("../../dat-source/teaching-methods.csv")

head(teach)

library(tidyverse)

teach_long <- teach %>% group_by_all() %>%
  summarize(n_subject = n()) %>%
  pivot_wider(names_from = Subject,
              values_from = n_subject,
              values_fill = 0)

library(nnet)
teach_mlr <- multinom(Subject ~ ., data = teach)

teach_mlr <- multinom(cbind(Arts, Math, Science) ~ ., data = teach_long)

library(VGAM)
teach_mlr <- vglm(Subject ~ ., data = teach, family = multinomial)

teach_mlr <- vglm(cbind(Arts, Math, Science) ~ ., data = teach_long, family = multinomial)

summary(teach_mlr)

anova(teach_mlr, type = 3, test = "LR")

exp(coef(teach_mlr))
exp(confint(teach_mlr))


logLik(teach_mlr)


# pearson test for lack of fit
e = residuals(teach_mlr, type = 'pearson')
x2 = sum(e^2)
1 - pchisq(x2, df)

# deviance test for lack of fit
g2 = deviance(teach_mlr)
df = df.residual(teach_mlr)
1 - pchisq(g2, df)

library(car)
vif(teach_mlr)
plot(teach_mlr)
```



```{r}
iris %>% head()

iris_mlr <- vglm(Species ~ ., data = iris, family = multinomial)
iris_mlr <- multinom(Species ~ ., data = iris)

summary(iris_mlr)
logLik(iris_mlr)
```




